{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1RUokIjWYgKVVLEhj9cwfaqrmUNdyuwol","timestamp":1726281523894}],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"96xkH81WR71O","executionInfo":{"status":"ok","timestamp":1709779005796,"user_tz":480,"elapsed":3721,"user":{"displayName":"SONIA KANG","userId":"07081313202246134692"}},"outputId":"33ea1734-9eb2-4fda-8b30-1ed6232dfd01"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 7,  3,  1,  1, 14, 11, 12,  2],\n","        [ 3, 15, 17, 17, 16,  2, 17,  1],\n","        [11, 12, 17, 12, 11,  3,  8, 18],\n","        [ 7, 16, 16,  0,  5,  7, 11,  6]])\n"]}],"source":["import torch\n","from torch import nn\n","\n","dummy_data = torch.randint(0, 19, (4, 8))\n","\n","print(dummy_data)"]},{"cell_type":"code","source":["import torch.nn.functional as F\n","\n","class Attention(nn.Module):\n","  def __init__(self, embedding_dim):\n","    super().__init__()\n","    self.query = nn.Linear(embedding_dim, embedding_dim)\n","    self.keys = nn.Linear(embedding_dim, embedding_dim)\n","    self.values = nn.Linear(embedding_dim, embedding_dim)\n","\n","  def forward(self, idx):\n","    # shape of idx ? [B, T, C], C = embedding dim\n","    B,T,C = idx.shape\n","    q = self.query(idx) # [B, T, C] -> [B, T, C]\n","    k = self.keys(idx) # [B, T, C] -> [B, T, C]\n","    # q @ k -> ignore batch dimension, only look at [T, C] x [T, C] <-- this wont work, since inner dims have to mathc\n","    # so... we transpose k from [B, T, C] -> [B, C, T]\n","    wei = q @ k.transpose(-2,-1) * C**-0.5 # [B, T, C] x [B, C, T] --> [B, T, T]\n","\n","    tril = torch.tril(torch.ones(T, T))\n","    wei = wei.masked_fill(tril == 0, float('-inf'))\n","    # wei shape: [B, T, T]\n","    wei = F.softmax(wei, dim=-1)\n","    v = self.values(idx) # [B, T, C]\n","    # wei shape: [B, T, T]\n","\n","    #[B, T, T] x [B, T, C] --> [B, T, C]\n","\n","    out = wei @ v\n","    return out\n","\n","class FFN(nn.Module):\n","  def __init__(self, embedding_dim):\n","    super().__init__()\n","    self.big = nn.Linear(embedding_dim, 4*embedding_dim)\n","    self.act = nn.ReLU()\n","    self.back_down = nn.Linear(4*embedding_dim, embedding_dim)\n","\n","  def forward(self, idx):\n","    # idx: shape = [B, T, C]\n","    out_proj = self.big(idx) # shape: [B, T, 4*C]\n","    act = self.act(out_proj) # shape: [B, T, 4*C]\n","    final = self.back_down(act) # shape: [B, T, C]\n","    return final\n","\n","class AttentionBlock(nn.Module):\n","  def __init__(self, embedding_dim):\n","    super().__init__()\n","    self.attn = Attention(embedding_dim)\n","    self.ffn = FFN(embedding_dim)\n","\n","  def forward(self, idx):\n","    # idx shape: [B, T, C]\n","    attended = self.attn(idx) # shape: [B, T, C]\n","    ffn_d = self.ffn(attended) # shape: [B, T, C]\n","    return ffn_d\n","\n","class GilmoreGirlsModel(nn.Module):\n","    def __init__(self, vocab_size, embedding_dim, max_seqlen=384, num_blocks=4):\n","        super().__init__()\n","        self.embeddings_table = nn.Embedding(vocab_size, embedding_dim)\n","        self.pos_emb = nn.Embedding(max_seqlen, embedding_dim)\n","        self.proj = nn.Linear(embedding_dim, vocab_size)\n","        self.blocks = nn.ModuleList([AttentionBlock(embedding_dim) for _ in range(num_blocks)])\n","        self.max_seqlen = max_seqlen\n","\n","    def forward(self, index):\n","        #index shape: [B, T]\n","        x = self.embeddings_table(index) # B, T, C\n","        B, T, C = x.shape\n","\n","        pe = self.pos_emb(torch.arange(T, device=index.device).repeat(B, 1))\n","\n","        x = x + pe\n","\n","        for block in self.blocks:\n","            x = x + block(x)\n","\n","        logits = self.proj(x)\n","        return logits"],"metadata":{"id":"pERJRSDgWNVC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.arange(4).repeat(4, 1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3f6B727MYV4e","executionInfo":{"status":"ok","timestamp":1709779546588,"user_tz":480,"elapsed":6,"user":{"displayName":"SONIA KANG","userId":"07081313202246134692"}},"outputId":"5ff39437-de46-4105-a3cf-c1983de08553"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0, 1, 2, 3],\n","        [0, 1, 2, 3],\n","        [0, 1, 2, 3],\n","        [0, 1, 2, 3]])"]},"metadata":{},"execution_count":38}]},{"cell_type":"code","source":["data # B, T, C\n","\n","pos_emb = torch.randn_like(data) # B, T, C\n","\n","embed = data + pos_emb"],"metadata":{"id":"cjhG_SzwXc16"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["attn = Attention(16)\n","\n","B, T, C = (1, 5, 16)\n","\n","data = torch.randn(B, T, C)\n","\n","attn(data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tEzhtKArRBPf","executionInfo":{"status":"ok","timestamp":1709779546588,"user_tz":480,"elapsed":5,"user":{"displayName":"SONIA KANG","userId":"07081313202246134692"}},"outputId":"93230e2d-949a-4dfd-bd96-6c41fded4f28"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[ 0.4889,  0.0213,  0.2273, -0.5746,  0.3502,  0.2317, -0.3004,\n","          -0.4665,  0.0458,  0.0026, -0.1012,  0.1075,  0.0457, -0.3787,\n","           0.6303, -0.3164],\n","         [ 0.3537,  0.2263, -0.5231, -0.2912, -0.4993,  0.4828,  0.3862,\n","          -0.1133,  0.4472,  0.2432, -0.1466,  0.2350, -0.2628,  0.2256,\n","           0.1077,  1.0802],\n","         [ 0.3368, -0.0499, -0.3979, -0.0053, -0.1191,  0.4282,  0.2202,\n","          -0.2333,  0.1812,  0.0992, -0.4765,  0.1799, -0.0421,  0.2814,\n","           0.1335,  0.7313],\n","         [ 0.2808, -0.3724, -0.1599,  0.0786,  0.1022,  0.2207,  0.0816,\n","          -0.4529,  0.1907,  0.0626, -0.3384,  0.2092,  0.1368, -0.0632,\n","           0.4214,  0.0902],\n","         [-0.0304, -0.3717, -0.2522,  0.1635, -0.1021,  0.2009,  0.1112,\n","          -0.6200,  0.2763,  0.3410, -0.2824,  0.1682, -0.0302, -0.0927,\n","           0.4609,  0.1211]]], grad_fn=<UnsafeViewBackward0>)"]},"metadata":{},"execution_count":40}]},{"cell_type":"code","source":["vocab_size = 20\n","embedding_dim = 10\n","\n","model = GilmoreGirlsModel(vocab_size, embedding_dim)\n","\n","dummy_data = torch.randint(0, vocab_size, (4, 8))\n","\n","embedded_data = model(dummy_data)\n","\n","print(embedded_data.shape)\n"],"metadata":{"id":"0eWxZ59FZBNP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709779546588,"user_tz":480,"elapsed":4,"user":{"displayName":"SONIA KANG","userId":"07081313202246134692"}},"outputId":"af8a9e7e-59d3-48b4-9399-332fac412efe"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([4, 8, 20])\n"]}]},{"cell_type":"code","source":["embedded_data.shape"],"metadata":{"id":"a-un9D9vdMrM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709779546588,"user_tz":480,"elapsed":3,"user":{"displayName":"SONIA KANG","userId":"07081313202246134692"}},"outputId":"f918554e-a0ea-45d7-e634-fe2d829106ef"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([4, 8, 20])"]},"metadata":{},"execution_count":42}]},{"cell_type":"code","source":["embedded_data[0,0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i31wrpHXaCs5","executionInfo":{"status":"ok","timestamp":1709779546588,"user_tz":480,"elapsed":3,"user":{"displayName":"SONIA KANG","userId":"07081313202246134692"}},"outputId":"b70d96de-3ebd-41a2-c4d1-b001a7218219"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([-0.4465,  1.3808, -1.5511,  0.0703,  0.3038,  0.7585,  1.4891, -0.1262,\n","         1.0671, -0.1898,  0.0757,  1.1880,  0.4566,  0.5843, -0.1075, -0.4119,\n","         0.2808,  0.2050,  1.3213, -1.0443], grad_fn=<SelectBackward0>)"]},"metadata":{},"execution_count":43}]},{"cell_type":"code","source":["#loss calculation\n","\n","input = torch.randint(0, 19, (4, 8))\n","targets = torch.randint(0, 19, (4, 8))\n","\n","m = GilmoreGirlsModel(20, 100, 8)\n","\n","logits = m(input) #B, T, C\n","B, T, C = logits.shape\n","logits = logits.view(B*T, C)\n","\n","targets = targets.view(B*T)\n","\n","loss = F.cross_entropy(logits, targets)\n","print(loss)\n","\n","#def loss_calc(idx, targets):\n","  #B, T, C = logits.shape\n"],"metadata":{"id":"Na46U8Osa2Df","executionInfo":{"status":"ok","timestamp":1709779547691,"user_tz":480,"elapsed":1,"user":{"displayName":"SONIA KANG","userId":"07081313202246134692"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"6ea82ad2-4258-461e-d695-78ec9dc7f839"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(3.2074, grad_fn=<NllLossBackward0>)\n"]}]},{"cell_type":"code","source":["#training loop\n","\n","batch_size = 128\n","m = GilmoreGirlsModel(20, 100, 8)\n","optimizer = torch.optim.AdamW(m.parameters(), lr = 1e-3)\n","for steps in range(10000):\n","    xb, yb = torch.randint(0, 19, (4, 8)), torch.randint(0, 19, (4, 8))\n","    logits = m(xb) #B, T, C\n","    B, T, C = logits.shape\n","    logits = logits.view(B*T, C) #B*T, C\n","\n","    yb = yb.view(B*T) #B*T\n","    loss = F.cross_entropy(logits, yb) #1\n","    # print(loss)\n","    loss.backward()\n","    optimizer.step()\n","  if steps%500 == 0:\n","      print('step', steps, 'loss', loss.item())\n","  optimizer.zero_grad()\n","\n","print(loss.item())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"id":"CuzMXaxle6WE","executionInfo":{"status":"error","timestamp":1709786193835,"user_tz":480,"elapsed":356,"user":{"displayName":"SONIA KANG","userId":"07081313202246134692"}},"outputId":"d3e7b8c9-06cd-4c41-95ff-28f2c3e418b4"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'GilmoreGirlsModel' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-87082e7175a1>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGilmoreGirlsModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamW\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msteps\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'GilmoreGirlsModel' is not defined"]}]},{"cell_type":"code","source":[],"metadata":{"id":"F-1_fc2fwtnx"},"execution_count":null,"outputs":[]}]}